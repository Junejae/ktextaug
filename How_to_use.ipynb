{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "driven-broadcasting",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# kTextAugmentation\n",
    "\n",
    "이 노트북은 kTextAugmentation 패키지를 사용하기 위한 예시입니다.\n",
    "documentation을 완성하기전까지는 이 노트북을 위주로 설명할 것 같습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-scottish",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### TextAugmentation() 사용하기\n",
    "패키지 0.1.9 버젼부턴 기본적으로 TextAugmentation() 을 사용하여 처리하는 것을 권장합니다. multiprocessing 을 이용하여 대용량의 데이터를 빠르게 처리할 수 있도록 만들었습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "speaking-latin",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type check False\n",
      "달리는 기차에는 중립이 없습니다. 이것은 미국 사회 운동가이자 역사가 하워드 진의 속담입니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "789e64fa240f42a19d52f0f0b50e88c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['프로그램 개발이 완료되면 서비스가 진행됩니다.', '도움말을 보려면 --help를 입력하십시오.']\n"
     ]
    }
   ],
   "source": [
    "from ktextaug import TextAugmentation\n",
    "\n",
    "sample_text = '달리는 기차 위에 중립은 없다. 미국의 사회 운동가이자 역사학자인 하워드 진이 남긴 격언이다.'\n",
    "sample_texts = ['프로그램 개발이 끝나고 서비스가 진행된다.', '도움말을 보고 싶다면 --help를 입력하면 된다.']\n",
    "agent = TextAugmentation(tokenize_fn=\"mecab\",\n",
    "                        num_processes=1) # num_process 가 -1 일시 자동으로 가능한 process의 절반으로 할당\n",
    "print(agent.generate(sample_text))     # default is back_translation\n",
    "print(agent.generate(sample_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-invention",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### 직접 import 해서 사용하기\n",
    "0.1.8 에서 사용하던 대로 직접 원하는 기능을 import 할 수 있습니다.\n",
    "\n",
    "현재 불러올 수 있는 함수는 다음과 같습니다. \n",
    "\"back_translate\",\n",
    "\"noise_add\",\n",
    "\"random_insert\",\n",
    "\"random_delete\",\n",
    "\"random_swap\",\n",
    "\"synonym_replace\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intense-forwarding",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bring_it_your_own' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-9-df39bcc0bd80>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"이 문장은 변형적 데이터 증강기법의 예시 문장입니다.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbring_it_your_own\u001B[0m   \u001B[0;31m# 토크나이저는 어떤 토크나이저를 사용하더라도 상관없습니다.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m result = random_swap(text_or_words=text,\n",
      "\u001B[0;31mNameError\u001B[0m: name 'bring_it_your_own' is not defined"
     ]
    }
   ],
   "source": [
    "from ktextaug import random_swap\n",
    "from random import Random\n",
    "\n",
    "text = \"이 문장은 변형적 데이터 증강기법의 예시 문장입니다.\"\n",
    "tokenizer = bring_it_your_own   # 토크나이저는 어떤 토크나이저를 사용하더라도 상관없습니다.\n",
    "\n",
    "result = random_swap(text_or_words=text,\n",
    "                     tokenize_fn=tokenizer.tokenize, \n",
    "                     rng=Random(seed=2021),\n",
    "                     n_swap=2) # random_swap 고유 파라메터. 토큰 시퀀스 내 두 단어의 위치를 변경하는 작업(random swap)을 2회 시행합니다. \n",
    "print(result)\n",
    "# ['이', '문장', '은', '예시', '적', '데이터', '기법', '증강', '의', '문장', '변형', '입니다', '.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-walnut",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### tokenize_fn \n",
    "\n",
    "ktextaug패키지는 tokenizer 내부에서 따로 wrapping 하지 않으며, <class 'function'> 형태의 tokenize 함수를 받습니다. 이미 너무 잘 만들어진 tokenizer 패키지들이 많은데, 여기서 불필요하게 wrapping 할 필요가 없다고 판단했습니다. 단, 사용자들이 원할 경우 사용할 수 있도록 get_tokenize_fn 를 구현해두었습니다. mecan, komoran이 설치되어있는 경우 사용할 수 있으며, subword의 경우 transformers 의 BertTokenizer을 가져와 사용합니다.\n",
    "\n",
    "(subword 경우 노이즈와 관련된 vocab을 구축해놓았기 때문에 다른 토크나이저에 비해 noise_add에서 훨씬 강건합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smart-woman",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'method'>\n",
      "['나', '는', '학교', '에서', '밥', '을', '먹', '었', '다', '.']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'java'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-71f135d30e5d>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokenize_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokenize_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"나는 학교에서 밥을 먹었다.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mtokenize_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_tokenize_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"komoran\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokenize_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"나는 학교에서 밥을 먹었다.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0mtokenize_fn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_tokenize_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"subword\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/home/projects/textaug/kTextAugmentation/ktextaug/tokenization_utils.py\u001B[0m in \u001B[0;36mget_tokenize_fn\u001B[0;34m(tokenizer_name, vocab_path)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtokenizer_name\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"komoran\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m         \u001B[0;32mfrom\u001B[0m \u001B[0mPyKomoran\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mKomoran\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m         \u001B[0mtokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mKomoran\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"STABLE\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_morphes_by_tags\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mtokenizer_name\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"mecab\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/PyKomoran/core.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, model_path, max_heap)\u001B[0m\n\u001B[1;32m     54\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpos_table\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mPos\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 56\u001B[0;31m         \u001B[0mjvm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minit_jvm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_heap\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     57\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_komoran\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjvm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_jvm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkr\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mco\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshineware\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnlp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpykomoran\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mKomoranEntryPoint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/PyKomoran/jvm.py\u001B[0m in \u001B[0;36minit_jvm\u001B[0;34m(max_heap, jar_path)\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[0mpy4j_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"{0}{1}py4j0.10.8.1.jar\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjar_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msep\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m     port = launch_gateway(jarpath=py4j_path,\n\u001B[0m\u001B[1;32m     43\u001B[0m                           \u001B[0mclasspath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclasspath\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m                           \u001B[0mjavaopts\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'-Dfile.encoding=UTF8'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'-ea'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'-Xmx{}m'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_heap\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/py4j/java_gateway.py\u001B[0m in \u001B[0;36mlaunch_gateway\u001B[0;34m(port, jarpath, classpath, javaopts, die_on_exit, redirect_stdout, redirect_stderr, daemonize_redirect, java_path, create_new_process_group, enable_auth)\u001B[0m\n\u001B[1;32m    320\u001B[0m         \u001B[0mpopen_kwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_create_new_process_group_kwargs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    321\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 322\u001B[0;31m     proc = Popen(command, stdout=PIPE, stdin=PIPE, stderr=stderr,\n\u001B[0m\u001B[1;32m    323\u001B[0m                  **popen_kwargs)\n\u001B[1;32m    324\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/subprocess.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001B[0m\n\u001B[1;32m    852\u001B[0m                             encoding=encoding, errors=errors)\n\u001B[1;32m    853\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 854\u001B[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001B[0m\u001B[1;32m    855\u001B[0m                                 \u001B[0mpass_fds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcwd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    856\u001B[0m                                 \u001B[0mstartupinfo\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcreationflags\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshell\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/subprocess.py\u001B[0m in \u001B[0;36m_execute_child\u001B[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001B[0m\n\u001B[1;32m   1700\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0merrno_num\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1701\u001B[0m                         \u001B[0merr_msg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrerror\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merrno_num\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1702\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mchild_exception_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merrno_num\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_msg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merr_filename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1703\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mchild_exception_type\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr_msg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1704\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'java'"
     ]
    }
   ],
   "source": [
    "from ktextaug.tokenization_utils import get_tokenize_fn\n",
    "\n",
    "# get_tokenize_fn 함수의 사용예시\n",
    "tokenize_fn = get_tokenize_fn(\"mecab\")\n",
    "print(type(tokenize_fn))\n",
    "print(tokenize_fn(\"나는 학교에서 밥을 먹었다.\"))\n",
    "tokenize_fn = get_tokenize_fn(\"komoran\")\n",
    "print(tokenize_fn(\"나는 학교에서 밥을 먹었다.\"))\n",
    "tokenize_fn = get_tokenize_fn(\"subword\")\n",
    "print(tokenize_fn(\"나는 학교에서 밥을 먹었다.\"))\n",
    "\n",
    "# 이러한 <class 'function'> 또는 <class 'method'> 형태의 함수들은 패키지 내 함수나 TextAugmentation 클래스에 사용됩니다.\n",
    "\n",
    "agent = TextAugmentation(tokenize_fn=tokenize_fn,\n",
    "#                         tokenize_fn=\"mecab\",\n",
    "                        num_processes=1) \n",
    "\n",
    "result = random_swap(text_or_words=text,\n",
    "                     tokenize_fn=lambda x: x.split(\" \"), # lambda로도 사용 가능\n",
    "                     rng=Random(seed=2021),\n",
    "                     n_swap=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-mouth",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### noise_generation 모듈 사용법\n",
    "\n",
    "노이즈 생성은 @hkjeon13(전현규) 의 노이즈 생성을 따랐습니다\n",
    "\n",
    "https://github.com/hkjeon13/noising-korean\n",
    "\n",
    "노이즈를 생성하는 방법은 총 3가지가 구현되어 있습니다.\n",
    "\n",
    "\"jamo_split\": 자모 분리(alphabet separation)에 의한 노이즈 추가 방법. 글자의 자음과 모음을 분리합니다. 단, 가독성을 위해 종성이 없으며 중성이  'ㅘ', 'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅗ' 가 아닐 경우 실행합니다(예: 안녕하세요 > 안녕ㅎㅏㅅㅔ요)\n",
    "\n",
    "\"vowel_change\": 모음 변형에 의한 노이즈 추가 방법. 글자의 모음을 변형시킵니다. 단, 가독성을 위해 종성이 없으며 중성이 'ㅏ', 'ㅑ', 'ㅓ', 'ㅕ', 'ㅗ', 'ㅛ', 'ㅜ', 'ㅠ' 일 경우 실행합니다(예: 안녕하세요 > 안녕햐세오).\n",
    "\n",
    "\"phonological_change\": 음운변화에 의한 노이즈 추가 방법. 발음을 바탕으로 단어를 변형시킵니다(너무 닮았다 > 너무 달맜다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "protected-heritage",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'noise_generation'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-f2297af4d773>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mnoise_generation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mtext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'행복한 가정은 모두가 닮았지만, 불행한 가정은 모두 저마다의 이유로 불행하다.'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m agent = TextAugmentation(tokenize_fn=\"mecab\",\n\u001B[1;32m      5\u001B[0m                         num_process=1) \n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'noise_generation'"
     ]
    }
   ],
   "source": [
    "import noise_generation\n",
    "\n",
    "text = '행복한 가정은 모두가 닮았지만, 불행한 가정은 모두 저마다의 이유로 불행하다.'\n",
    "agent = TextAugmentation(tokenize_fn=\"mecab\",\n",
    "                        num_process=1) \n",
    "print(agent.generate(text,\n",
    "                     mode=\"noise_add\",\n",
    "                     noise_mode=\"jamo_split\"))     \n",
    "# >> 행복한 ㄱㅏ정은 모두ㄱㅏ 닮았ㅈㅣ만, 불행한 ㄱㅏ정은 모두 ㅈㅓㅁㅏㄷㅏ의 ㅇㅣ유로 불행ㅎㅏㄷㅏ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-colombia",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "\n",
    "**노이즈 생성의 변형 예시**\n",
    "\n",
    "```python\n",
    "text = '행복한 가정은 모두가 닮았지만, 불행한 가정은 모두 저마다의 이유로 불행하다.'\n",
    "[original]  행복한 가정은 모두가 닮았지만, 불행한 가정은 모두 저마다의 이유로 불행하다.\n",
    "\n",
    "[jamo_split, prob=1] 행복한 ㄱㅏ정은 모두ㄱㅏ 닮았ㅈㅣ만, 불행한 ㄱㅏ정은 모두 ㅈㅓㅁㅏㄷㅏ의 ㅇㅣ유로 불행ㅎㅏㄷㅏ.\n",
    "\n",
    "[vowel_change, prob=1] 행복한 갸정은 묘듀갸 닮았지만, 불행한 갸정은 묘듀 져먀댜의 이우료 불행햐댜.\n",
    "\n",
    "[phonological_change, prob=1] 행복한 가정은 모두가 달맜지만, 불행한 가정은 모두 저마다의 이유로 불행하다.\n",
    "```\n",
    "\n",
    "#### 기타\n",
    "\n",
    "- 'phonological_change' 방법은 현재 비음화, 유음화, 구개음화, 연음 등을 구현하고 있으며, 추후 확대될 예정입니다(누락된 규칙이 있을 수 있으니, 발견 시 피드백 주시면 감사하겠습니다).\n",
    "- prob는 변형 가능한 글자들에 대해서 해당 확률만큼 확률적으로 실행됩니다(prob가 1이라고 해서 모든 텍스트가 변경되는 것이 아닙니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-nursery",
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}